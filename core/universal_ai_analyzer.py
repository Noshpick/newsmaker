from config.settings import AI_PROVIDER, AI_API_KEY, AI_MODEL
import json
import aiohttp


class UniversalAIAnalyzer:

    def __init__(self):
        self.provider = AI_PROVIDER.lower()
        self.api_key = AI_API_KEY
        self.model = AI_MODEL

        if self.provider == 'claude':
            from anthropic import Anthropic
            self.client = Anthropic(api_key=self.api_key)
        elif self.provider == 'gemini':
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            self.client = genai.GenerativeModel(self.model)
        elif self.provider == 'groq':
            from groq import Groq
            self.client = Groq(api_key=self.api_key)
        elif self.provider == 'ollama':
            self.base_url = "http://localhost:11434"

    async def _call_claude(self, prompt: str, max_tokens: int = 1000) -> str:
        response = self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text

    async def _call_gemini(self, prompt: str) -> str:
        response = self.client.generate_content(prompt)
        return response.text

    async def _call_groq(self, prompt: str, max_tokens: int = 1000) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens,
            temperature=0.7
        )
        return response.choices[0].message.content

    async def _call_ollama(self, prompt: str) -> str:
        # –í—ã–∑–æ–≤ Ollama (–ª–æ–∫–∞–ª—å–Ω–æ)
        async with aiohttp.ClientSession() as session:
            async with session.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "stream": False
                    }
            ) as response:
                result = await response.json()
                return result['response']

    async def generate(self, prompt: str, max_tokens: int = 1000) -> str:
        try:
            if self.provider == 'claude':
                return await self._call_claude(prompt, max_tokens)
            elif self.provider == 'gemini':
                return await self._call_gemini(prompt)
            elif self.provider == 'groq':
                return await self._call_groq(prompt, max_tokens)
            elif self.provider == 'ollama':
                return await self._call_ollama(prompt)
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.provider}")
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {self.provider}: {str(e)}")

    async def analyze_article(self, title: str, content: str, brand_info: dict = None) -> dict:

        brand_context = ""
        if brand_info and brand_info.get('brand_name'):
            brand_context = f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –±—Ä–µ–Ω–¥–∞: {brand_info.get('brand_name')}"
            if brand_info.get('brand_tone'):
                brand_context += f"\n–¢–æ–Ω –±—Ä–µ–Ω–¥–∞: {brand_info.get('brand_tone')}"

        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É —Å—Ç–∞—Ç—å—é/–Ω–æ–≤–æ—Å—Ç—å –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –°–¢–†–û–ì–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.
{brand_context}

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}

–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:
{content[:3000]}

–í–µ—Ä–Ω–∏ JSON —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:
{{
    "summary": "–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö",
    "sentiment": "positive/negative/neutral - –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —É–ø–æ–º–∏–Ω–∞–µ–º–æ–º—É –±—Ä–µ–Ω–¥—É/–∫–æ–º–ø–∞–Ω–∏–∏",
    "key_points": ["–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 1", "–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 2", "–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 3"],
    "relevance_score": —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 10 (–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç—å—è –≤–∞–∂–Ω–∞ –¥–ª—è –±—Ä–µ–Ω–¥–∞),
    "main_theme": "–æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ —Å—Ç–∞—Ç—å–∏ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º"
}}

–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ markdown."""

        try:
            result_text = await self.generate(prompt, max_tokens=1000)

            result_text = result_text.strip()
            if result_text.startswith('```'):
                lines = result_text.split('\n')
                result_text = '\n'.join(lines[1:-1])
            if result_text.startswith('json'):
                result_text = result_text[4:].strip()

            result = json.loads(result_text)
            return result

        except json.JSONDecodeError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–ü–æ–ª—É—á–µ–Ω —Ç–µ–∫—Å—Ç: {result_text[:200]}")
            return {
                'summary': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å—é',
                'sentiment': 'neutral',
                'key_points': [],
                'relevance_score': 5,
                'main_theme': '–æ–±—â–µ–µ'
            }
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {
                'summary': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å—é',
                'sentiment': 'neutral',
                'key_points': [],
                'relevance_score': 5,
                'main_theme': '–æ–±—â–µ–µ'
            }

    async def generate_posts(self, article_data: dict, platforms: list, brand_info: dict = None) -> dict:
        from config.settings import PLATFORMS

        print(f"üîç DEBUG: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º: {platforms}")

        brand_context = ""
        if brand_info and brand_info.get('brand_name'):
            brand_context = f"–ë—Ä–µ–Ω–¥: {brand_info.get('brand_name')}\n"
            if brand_info.get('brand_tone'):
                brand_context += f"–¢–æ–Ω –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏: {brand_info.get('brand_tone')}\n"

        platform_requirements = []
        for platform in platforms:
            platform_info = PLATFORMS.get(platform, {})
            req = f"- {platform_info.get('name', platform)}: "
            req += f"–º–∞–∫—Å. {platform_info.get('max_length')} —Å–∏–º–≤–æ–ª–æ–≤"
            if platform_info.get('formal'):
                req += ", —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å"
            if platform_info.get('emoji'):
                req += ", –º–æ–∂–Ω–æ —ç–º–æ–¥–∑–∏"
            platform_requirements.append(req)

        sentiment_context = {
            'positive': '–≠—Ç–æ –ü–û–ó–ò–¢–ò–í–ù–ê–Ø –Ω–æ–≤–æ—Å—Ç—å - –ø–æ–¥—á–µ—Ä–∫–Ω–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∏ —É—Å–ø–µ—Ö–∏',
            'negative': '–≠—Ç–æ –ù–ï–ì–ê–¢–ò–í–ù–ê–Ø –Ω–æ–≤–æ—Å—Ç—å - –±—É–¥—å –æ—Å—Ç–æ—Ä–æ–∂–µ–Ω, –ø—Ä–µ–¥–ª–æ–∂–∏ –∫–∞–∫ –∫–æ–º–ø–∞–Ω–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–¥ –ø—Ä–æ–±–ª–µ–º–æ–π',
            'neutral': '–≠—Ç–æ –ù–ï–ô–¢–†–ê–õ–¨–ù–ê–Ø –Ω–æ–≤–æ—Å—Ç—å - –±—É–¥—å –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–º'
        }

        json_example = {}
        for platform in platforms:
            json_example[platform] = {
                "content": "—Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞",
                "hashtags": "#—Ö–µ—à—Ç–µ–≥1 #—Ö–µ—à—Ç–µ–≥2"
            }
        json_example_str = json.dumps(json_example, ensure_ascii=False, indent=2)

        prompt = f"""{brand_context}
–ò—Å—Ö–æ–¥–Ω–∞—è —Å—Ç–∞—Ç—å—è:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article_data.get('title')}
–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {article_data.get('summary')}
–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã: {', '.join(article_data.get('key_points', []))}

–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sentiment_context.get(article_data.get('sentiment', 'neutral'))}

–°–æ–∑–¥–∞–π –ø–æ—Å—Ç—ã –¢–û–õ–¨–ö–û –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º: {', '.join(platforms)}
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã:
{chr(10).join(platform_requirements)}

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ (–¢–û–õ–¨–ö–û –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º: {', '.join(platforms)}):
{json_example_str}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –°–æ–∑–¥–∞–π –ø–æ—Å—Ç—ã –¢–û–õ–¨–ö–û –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º: {', '.join(platforms)}
- –ö–∞–∂–¥—ã–π –ø–æ—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –£–ù–ò–ö–ê–õ–¨–ù–´–ú
- Telegram –∏ VK: –±–æ–ª–µ–µ –∂–∏–≤—ã–µ, —Å —ç–º–æ–¥–∑–∏
- LinkedIn –∏ –ø—Ä–µ—Å—Å-—Ä–µ–ª–∏–∑: –¥–µ–ª–æ–≤–æ–π —Å—Ç–∏–ª—å
- Twitter: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ
- –î–æ–±–∞–≤—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ö–µ—à—Ç–µ–≥–∏ (3-5 —à—Ç—É–∫)

–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º {', '.join(platforms)}, –±–µ–∑ markdown, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º."""

        try:
            result_text = await self.generate(prompt, max_tokens=2000)

            result_text = result_text.strip()
            if result_text.startswith('```'):
                lines = result_text.split('\n')
                result_text = '\n'.join(lines[1:-1])
            if result_text.startswith('json'):
                result_text = result_text[4:].strip()

            print(f"üîç DEBUG: –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç AI:\n{result_text[:500]}")

            posts = json.loads(result_text)

            print(f"üîç DEBUG: –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã: {list(posts.keys())}")

            filtered_posts = {k: v for k, v in posts.items() if k in platforms}

            print(f"üîç DEBUG: –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {list(filtered_posts.keys())}")

            for platform in platforms:
                if platform not in filtered_posts:
                    print(f"‚ö†Ô∏è WARNING: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ {platform} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ—Ç–≤–µ—Ç–µ AI, –¥–æ–±–∞–≤–ª—è—é –∑–∞–≥–ª—É—à–∫—É")
                    filtered_posts[platform] = {
                        'content': f"{article_data.get('title')}\n\n{article_data.get('summary')}",
                        'hashtags': '#–Ω–æ–≤–æ—Å—Ç–∏'
                    }

            return filtered_posts

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤: {e}")
            print(f"–û—Ç–≤–µ—Ç AI: {result_text if 'result_text' in locals() else 'N/A'}")
            simple_post = {
                'content': f"{article_data.get('title')}\n\n{article_data.get('summary')}",
                'hashtags': '#–Ω–æ–≤–æ—Å—Ç–∏'
            }
            return {platform: simple_post for platform in platforms}

    async def suggest_posting_schedule(self, posts: dict, sentiment: str) -> dict:

        prompt = f"""–£ –Ω–∞—Å –µ—Å—Ç—å –ø–æ—Å—Ç—ã –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö: {', '.join(posts.keys())}
–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏: {sentiment}

–ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏. –£—á—Ç–∏:
- –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ª—É—á—à–µ –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —É—Ç—Ä–æ–º/–¥–Ω—ë–º
- –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ - –≤–µ—á–µ—Ä–æ–º, –∫–æ–≥–¥–∞ –º–µ–Ω—å—à–µ –æ—Ö–≤–∞—Ç
- Telegram –∏ VK - –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É
- LinkedIn - –ª—É—á—à–µ –≤ —Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã (10-16)
- –ü—Ä–µ—Å—Å-—Ä–µ–ª–∏–∑—ã - —É—Ç—Ä–æ —Ä–∞–±–æ—á–µ–≥–æ –¥–Ω—è

–í–µ—Ä–Ω–∏ JSON:
{{
    "telegram": {{"time_slot": "—Å–µ–≥–æ–¥–Ω—è 14:00", "priority": 1, "reason": "–ø–æ—á–µ–º—É"}},
    "vk": {{"time_slot": "—Å–µ–≥–æ–¥–Ω—è 15:00", "priority": 2, "reason": "–ø–æ—á–µ–º—É"}}
}}

–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON, –±–µ–∑ markdown."""

        try:
            result_text = await self.generate(prompt, max_tokens=1000)

            result_text = result_text.strip()
            if result_text.startswith('```'):
                lines = result_text.split('\n')
                result_text = '\n'.join(lines[1:-1])
            if result_text.startswith('json'):
                result_text = result_text[4:].strip()

            schedule = json.loads(result_text)
            return schedule

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return {platform: {"time_slot": "—Å–µ–≥–æ–¥–Ω—è 14:00", "priority": i + 1}
                    for i, platform in enumerate(posts.keys())}

AIAnalyzer = UniversalAIAnalyzer